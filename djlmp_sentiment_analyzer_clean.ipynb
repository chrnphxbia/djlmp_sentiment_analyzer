{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40b90843"
      },
      "source": [
        "<img src=\"http://meusite.mackenzie.br/rogerio/mackenzie_logo/UPM.2_horizontal_vermelho.jpg\"  width=300, align=\"right\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rYx9D4GZA5o9",
        "cellView": "form"
      },
      "source": [
        "#@title **Identificação do Grupo**\n",
        "\n",
        "#@markdown Integrantes do Grupo, nome completo em ordem alfabética (*informe \\<RA\\>,\\<nome\\>*)\n",
        "Aluno1 = '10402412, Diego Oliveira Aluizio' #@param {type:\"string\"}\n",
        "Aluno2 = '10396490, Jônatas Garcia de Oliveira' #@param {type:\"string\"}\n",
        "Aluno3 = '10403046, Livia Alabarse dos Santos' #@param {type:\"string\"}\n",
        "Aluno4 = '10403028, Marina Scabello Martin' #@param {type:\"string\"}\n",
        "Aluno5 = '10265432, Pedro Henrique Araujo Farias' #@param {type:\"string\"}\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Assinale aqui a sua opção de Projeto\n",
        "Projeto = \"IA Aplicada a Documentos: Uso de Grandes Modelos de Linguagem Abertos\" #@param [\"IA Aplicada a Imagens: Uso de Modelos de Redes Neurais\", \"IA Aplicada a Documentos: Uso de Grandes Modelos de Linguagem Abertos\"]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-MbC50IHTmh3",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Resumo**"
      ],
      "metadata": {
        "id": "yxYbSf6mVM7y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "O objetivo deste *notebook* é desenvolver o treinamento de um modelo para a classificação de textos com base em seu sentimento, podendo ser classificados como **positivo**, **neutro** ou **negativo**, tarefa conhecida como **análise de sentimento**. Os dados utilizados para treinamento do modelo são uma amostra do *dataset* **Tweet_Eleições_2022**. As bibliotecas e ferramentas de IA utilizadas foram a ***Transformers***, fornecida pela ***Hugging Face***, e o ***TensorFlow***, fornecido pela ***Google***. Como resultado, obtivemos um modelo com 89,85% de acurácia nos testes, que foi disponibilizado na plataforma do *Hugging Face*."
      ],
      "metadata": {
        "id": "809qwZVlzJ_r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Bibliotecas utilizadas**"
      ],
      "metadata": {
        "id": "pveqZ5g0nS1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from transformers import AutoTokenizer, TFAutoModelForSequenceClassification, create_optimizer"
      ],
      "metadata": {
        "id": "VJB2Qjj9h8Qn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Apresentação dos dados**"
      ],
      "metadata": {
        "id": "ctroSu6jNABS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Os dados utilizados foram obtidos a partir do *dataset* [Tweet_Eleições_2022](https://github.com/ciberdem/Tweets_Eleicoes_2022) (SILVA *et al*., 2024), que reúne aproximadamente 9,5 milhões de tweets coletados ao longo do processo eleitoral brasileiro de 2022, via API oficial do *X*, antigo *Twitter*.\n",
        "\n",
        "Os dados foram pré-processados a partir das seguintes atividades: remoção de duplicatas, remoção de ruídos e anonimização de usuários, bem como seleção temporal, restringindo o conjunto à *tweets* publicados no dia 8 de janeiro de 2023. O resultado do pré-processamento foi um conjunto de 984 *tweets*.\n",
        "\n",
        "Os integrantes do projeto realizaram anotação manual dos dados de acordo com o sentimento de cada *tweet* analisado. Você pode acessar a planilha de dados utilizados para treinamento neste [link](https://docs.google.com/spreadsheets/d/1wklfGXQpK6i5W9hOcYyIxT1BcdkuN-Ik/edit?usp=drive_link&ouid=102543127324810311691&rtpof=true&sd=true)."
      ],
      "metadata": {
        "id": "Vf642LN0zGVx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "tweets_file_id = \"1wklfGXQpK6i5W9hOcYyIxT1BcdkuN-Ik\"\n",
        "url_tweets = f\"https://drive.google.com/uc?id={tweets_file_id}\"\n",
        "\n",
        "df = pd.read_excel(url_tweets)\n",
        "display(df)"
      ],
      "metadata": {
        "id": "5uYdR0EdWKDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Preparação e transformação dos dados**"
      ],
      "metadata": {
        "id": "GDzwn_5AMZ52"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As únicas colunas interessantes para treinamento do modelo são `text` e `Sentimento`, portanto a coluna `conversation_id` será **removida**."
      ],
      "metadata": {
        "id": "f768HH0guY4q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.drop('conversation_id', axis=1)\n",
        "display(df)\n",
        "print(f\"\\nDistribuição dos sentimentos:\\n{df['Sentimento'].value_counts()}\")"
      ],
      "metadata": {
        "id": "3WHgFkjcXKW0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida, realizamos o ***label encoding*** da coluna `Sentimento`, a qual representa nossa variável objetivo."
      ],
      "metadata": {
        "id": "g17UKSDhuwK6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {\"POSITIVO\": 0, \"NEUTRO\": 1, \"NEGATIVO\": 2}\n",
        "df['sentimento'] = df['Sentimento'].map(label_map)\n",
        "df = df.drop('Sentimento', axis=1)\n",
        "display(df)"
      ],
      "metadata": {
        "id": "8Uu_czHjGam2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por fim, vamos separar os dados em **três conjuntos**:\n",
        "- **Treinamento**: utilizados para aprendizagem do modelo durante o treinamento;\n",
        "- **Validação**: utilizados para validação da aprendizagem do modelo durante o treinamento;\n",
        "- **Teste**: utilizados para avaliação do modelo após o treinamento."
      ],
      "metadata": {
        "id": "BjsBgkl8vF2k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_val_df, test_df = train_test_split(\n",
        "    df, test_size=0.2, random_state=42, stratify=df['sentimento']\n",
        ")\n",
        "\n",
        "train_df, val_df = train_test_split(\n",
        "    train_val_df, test_size=0.25, random_state=42, stratify=train_val_df['sentimento']\n",
        ")"
      ],
      "metadata": {
        "id": "5iKEMGIfG2oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Tamanho do conjunto de Treino: {len(train_df)}\")\n",
        "display(train_df)\n",
        "\n",
        "print(f\"Tamanho do conjunto de Validação: {len(val_df)}\")\n",
        "display(val_df)\n",
        "\n",
        "print(f\"Tamanho do conjunto de Teste: {len(test_df)}\")\n",
        "display(test_df)"
      ],
      "metadata": {
        "id": "q_5mGTE9IU_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configuração e Treinamento do Modelo**"
      ],
      "metadata": {
        "id": "mnJHmydNNfl0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Modelo pré-treinado**\n",
        "\n",
        "O modelo pré-treinado utilizado para desenvolvimento do modelo deste *notebook* é o **BERTimbau Base**, um modelo baseado em BERT para análise de linguagem natural em português brasileiro."
      ],
      "metadata": {
        "id": "reSTc_H-Dw2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BERTimbau: *Tokenizer* e *Encoding* dos dados**"
      ],
      "metadata": {
        "id": "m8qFLxhKx9xM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para utilizar o BERTimbau, precisamos utilizar também seu ***tokenizer*** para **converter texto em sequências de tokens** que o modelo BERTimbau entende, e vice-versa:"
      ],
      "metadata": {
        "id": "wBAAHLbaxGPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('neuralmind/bert-base-portuguese-cased')"
      ],
      "metadata": {
        "id": "kn3N2gq6JOZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "A função `encode_texts` utiliza o ***tokenizer*** para preparar os dados para entrada no modelo BERTimbau, garantindo que todos tenham um comprimento fixo (max_len). Note que passamos `return_tensors='tf'` como argumento pois estamos utilizando o **TensorFlow**."
      ],
      "metadata": {
        "id": "Al_n2MW5xRZz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_texts(tokenizer, texts, max_len):\n",
        "    return tokenizer(\n",
        "        texts.tolist(),\n",
        "        max_length=max_len,\n",
        "        truncation=True,\n",
        "        padding='max_length',\n",
        "        return_attention_mask=True,\n",
        "        return_token_type_ids=False,\n",
        "        return_tensors='tf'\n",
        "    )"
      ],
      "metadata": {
        "id": "cS5IU3AoJprU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aplicando o *encoding* aos conjuntos:"
      ],
      "metadata": {
        "id": "NHK-wcfw4GLo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "\n",
        "train_x = encode_texts(tokenizer, train_df['text'], MAX_LEN)\n",
        "val_x = encode_texts(tokenizer, val_df['text'], MAX_LEN)\n",
        "test_x = encode_texts(tokenizer, test_df['text'], MAX_LEN)"
      ],
      "metadata": {
        "id": "15kMhkLoJyf4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformando os dados e rótulos em pipelines de dados `tf.data` para serem alimentados no treinamento e avaliação pelo `TensorFlow`, embaralhando o conjunto de treinamento:"
      ],
      "metadata": {
        "id": "FZnyUGN34LXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_y = train_df['sentimento'].to_numpy()\n",
        "val_y = val_df['sentimento'].to_numpy()\n",
        "test_y = test_df['sentimento'].to_numpy()"
      ],
      "metadata": {
        "id": "7yYxFUZJKAeL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset_dict = {key: train_x[key] for key in ['input_ids', 'attention_mask']}\n",
        "val_dataset_dict = {key: val_x[key] for key in ['input_ids', 'attention_mask']}\n",
        "test_dataset_dict = {key: test_x[key] for key in ['input_ids', 'attention_mask']}"
      ],
      "metadata": {
        "id": "RNh6z0R4KVQ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 32\n",
        "\n",
        "train_tf_dataset = tf.data.Dataset.from_tensor_slices((train_dataset_dict, train_y)).shuffle(len(train_df)).batch(BATCH_SIZE)\n",
        "val_tf_dataset = tf.data.Dataset.from_tensor_slices((val_dataset_dict, val_y)).batch(BATCH_SIZE)\n",
        "test_tf_dataset = tf.data.Dataset.from_tensor_slices((test_dataset_dict, test_y)).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "dYO4AkegKfXQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note duas operações essenciais:\n",
        "- `input_ids`: Mapeando para os tensores dos IDs dos tokens.\n",
        "- `attention_mask`: Mapeando para os tensores das máscaras de atenção.\n",
        "\n",
        "Esses mapeamentos são extremamente importantes para que o modelo compreenda e processe os dados."
      ],
      "metadata": {
        "id": "TflZ-5tY_cS5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **BERTimbau: Carregando o Modelo**"
      ],
      "metadata": {
        "id": "YwxdMowM5Ojg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Carregamos o modelo BERTimbau (`\"neuralmind/bert-base-portuguese-cased\"`) e definimos um **novo modelo**, utilizando o BERTimbau como modelo pré-treinado, adicionando uma camada de classificação no topo, ainda não treinada, com apenas **3 classificações possíveis** (`num_labels=3`), as quais classificarão o sentimento do texto analisado."
      ],
      "metadata": {
        "id": "LIxkOdfT5Zcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_NAME = \"neuralmind/bert-base-portuguese-cased\"\n",
        "id_to_label = {v: k for k, v in label_map.items()}\n",
        "\n",
        "model = TFAutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=3,\n",
        "    id2label=id_to_label,\n",
        "    label2id=label_map\n",
        ")"
      ],
      "metadata": {
        "id": "zLVAlctKLAIP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Em seguida, **congelamos as camadas de *embedding*** e **8 camadas de *encoder*** do BERTimbau com **objetivo de impedir que os pesos dessas camadas sejam atualizados durante o processo de *fine-tuning***, preservando o conhecimento do BERTimbau e reduzindo o número de parâmetros a serem treinados, o que torna o treinamento deste modelo mais rápido."
      ],
      "metadata": {
        "id": "M9M_Oj876iQY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_main_layer = model.layers[0]\n",
        "bert_main_layer.embeddings.trainable = False\n",
        "\n",
        "NUM_LAYERS_TO_FREEZE = 8\n",
        "\n",
        "if NUM_LAYERS_TO_FREEZE > 0 and hasattr(bert_main_layer, 'encoder'):\n",
        "    print(f\"Congelando as primeiras {NUM_LAYERS_TO_FREEZE} camadas do encoder BERT.\")\n",
        "    for i in range(NUM_LAYERS_TO_FREEZE):\n",
        "        if i < len(bert_main_layer.encoder.layer):\n",
        "            bert_main_layer.encoder.layer[i].trainable = False\n",
        "            print(f\"Encoder layer {i} congelada: {not bert_main_layer.encoder.layer[i].trainable}\")\n",
        "        else:\n",
        "            print(f\"Aviso: Tentativa de congelar camada {i}, mas o encoder tem apenas {len(bert_main_layer.encoder.layer)} camadas.\")\n",
        "            break\n",
        "else:\n",
        "    print(\"Nenhuma camada do encoder para congelar ou encoder não encontrado como esperado.\")"
      ],
      "metadata": {
        "id": "wD6fuMv_Lt_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definindo alguns **hiperparâmetros** do modelo, como **número de épocas**, **taxa de aprendizagem** e **otimizador** utilizados:"
      ],
      "metadata": {
        "id": "h_oAaU5-7nhC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 10\n",
        "LEARNING_RATE = 2e-5\n",
        "\n",
        "num_train_steps = (len(train_df) // BATCH_SIZE) * EPOCHS\n",
        "\n",
        "optimizer, schedule = create_optimizer(\n",
        "    init_lr=LEARNING_RATE,\n",
        "    num_warmup_steps=0,\n",
        "    num_train_steps=num_train_steps,\n",
        "    weight_decay_rate=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "YRch7FwpMg7N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Agora, vamos definir a função de perda a ser minimizada e sua métrica de desempenho. Por fim, compilamos o modelo."
      ],
      "metadata": {
        "id": "Lk4P8CgGCc1h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "metrics = [tf.keras.metrics.SparseCategoricalAccuracy('accuracy')]\n",
        "\n",
        "model.compile(optimizer=optimizer, loss=loss_fn, metrics=metrics)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "kfCzUkvzM_p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Obs.: Algo importante de se comentar é o número de parâmetros na camada `dropout_75`. Essa camada não apresenta parâmetros a serem treinados, pois seu único propósito é **desligar aleatoriamente alguns neurônios da rede, evitando *overfitting***."
      ],
      "metadata": {
        "id": "AKEN3sV5CxK0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como estávamos enfrentando **sérios problemas com *overfitting* durante o treinamento do modelo**, definimos também o ***early_stopping* e seus parâmetros**:"
      ],
      "metadata": {
        "id": "U9FMVhulDPmb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "fXn1-QEfuY0P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Treinamento do Modelo**"
      ],
      "metadata": {
        "id": "cItK-_rPDecE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos, finalmente, treinar nosso modelo!\n",
        "\n",
        "Explicando brevemente os argumentos utilizados na função `fit`:\n",
        "- `train_df_dataset`: Utilizamos o conjunto de **treinamento** como *dataset* normalizado para treinamento pelo modelo;\n",
        "- `validation_data=val_tf_dataset`: Utilizamos o `val_tf_dataset` como *dataset* normalizado para validação do treinamento do modelo;\n",
        "- `epochs=EPOCHS`: Definimos o número de épocas, estabelecido como **10 épocas**;\n",
        "- `batch_size=BATCH_SIZE`: Definimos o tamanho do lote para treinamento;\n",
        "- `callbacks=[early_stopping]`: Passamos a nossa função de *Early Stopping* definida na célula anterior para evitar *overfitting*."
      ],
      "metadata": {
        "id": "hyq9SWtgFbvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_tf_dataset,\n",
        "    validation_data=val_tf_dataset,\n",
        "    epochs=EPOCHS,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ],
      "metadata": {
        "id": "aHhIC0vSNAnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Avaliação do modelo**\n",
        "\n"
      ],
      "metadata": {
        "id": "p1Evo4PmNhBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Com base nas informações de treinamento armazenadas na variável `history`, vamos plotar gráficos de *loss* e *acurácia* para avaliar o treinamento do modelo:"
      ],
      "metadata": {
        "id": "qhtw6h40Finu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['loss'], label='Loss Treino')\n",
        "plt.plot(history.history['val_loss'], label='Loss Validação')\n",
        "plt.title('Histórico de Loss')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['accuracy'], label='Acurácia Treino')\n",
        "plt.plot(history.history['val_accuracy'], label='Acurácia Validação')\n",
        "plt.title('Histórico de Acurácia')\n",
        "plt.xlabel('Épocas')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "k47Blm2lPQRS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como é possível observar, o modelo apresenta ***loss* decrescente** para o **conjunto de treinamento**. Quanto ao **conjunto de validação**, a ***loss* decai até a sexta época**, onde acaba **estagnando até o fim do treinamento** (alerta para possível *overfitting*).\n",
        "\n",
        "Quanto à acurácia, esta é **crescente tanto para o conjunto de treinamento quanto para o de validação**. Curiosamente, a **acurácia do conjunto de validação parte de valores muito altos**, iniciando acima de 80%. A mesma tendência a *overfitting* se observa no gráfico de acurácia.\n",
        "\n",
        "Ainda que essa tendência seja recorrente, é importante observar que sua magnitude não se demonstra alarmante. Sendo assim, não é um modelo perfeito, mas também não é um modelo péssimo.\n",
        "\n",
        "Dado a pequena quantidade de dados da amostra, consideramos satisfatórios os resultados apresentados nos gráficos de *loss* e *accuracy*;"
      ],
      "metadata": {
        "id": "3WNMoPxKFzee"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(test_tf_dataset, verbose=1)\n",
        "print(f\"Acurácia no Teste: {test_accuracy:.4f}\")\n",
        "print(f\"Loss no Teste: {test_loss:.4f}\")"
      ],
      "metadata": {
        "id": "bWedlA56QsQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(test_dataset_dict, batch_size=BATCH_SIZE)\n",
        "predicted_logits = predictions.logits\n",
        "predicted_labels_int = np.argmax(predicted_logits, axis=1)\n",
        "target_names = [id_to_label[i] for i in range(3)]\n",
        "print(classification_report(test_y, predicted_labels_int, target_names=target_names, digits=4))"
      ],
      "metadata": {
        "id": "AJlRYAWpQ3wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quanto ao *classification report*, o modelo apresenta bons valores para as métricas de *precision* e *recall* (> 80%). O ***f1-score***, particularmente, se mantém **acima de 85%**."
      ],
      "metadata": {
        "id": "lqdyfP88Hc3w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Consumo do Modelo**"
      ],
      "metadata": {
        "id": "ViQfwNxkNj0C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Salvando o Modelo**"
      ],
      "metadata": {
        "id": "F5Pw-KwdIz3e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para consumir o modelo em uma aplicação, inicialmente salvamos o modelo e realizamos o *download* dos arquivos com a intenção de realizar o *upload* no ***GitHub***, de modo que a aplicação acessasse o modelo localmente:"
      ],
      "metadata": {
        "id": "yxYoZDT-H7ol"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OUTPUT_MODEL_DIR = \"./modelo_sentimento_bertimbau_finetuned_tf\"\n",
        "\n",
        "model.save_pretrained(OUTPUT_MODEL_DIR)\n",
        "tokenizer.save_pretrained(OUTPUT_MODEL_DIR)\n",
        "print(f\"Modelo e tokenizador salvos em: {OUTPUT_MODEL_DIR}\")"
      ],
      "metadata": {
        "id": "jMQcpreFqRnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entretanto, por ser um arquivo muito grande, o **modelo não pôde ser enviado ao *GitHub***. Sendo assim, optamos por publicar o modelo na plataforma do ***Hugging Face***:"
      ],
      "metadata": {
        "id": "htCMvs7vILeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q huggingface_hub"
      ],
      "metadata": {
        "id": "-sFQcPh222Gs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "B2Oc0zli28bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "repo_id = \"chrnphxbia/djmlp_tiny_analise_sentimento\"\n",
        "\n",
        "model.push_to_hub(\n",
        "    repo_id,\n",
        "    commit_message=\"Upload do modelo via Colab\",\n",
        "    private=False,\n",
        "    create_repo=True\n",
        ")\n",
        "\n",
        "tokenizer.push_to_hub(\n",
        "    repo_id,\n",
        "    commit_message=\"Update do tokenizer via Colab\",\n",
        "    private=False\n",
        ")\n",
        "\n",
        "print(f\"Modelo e tokenizador enviados para: https://huggingface.co/{repo_id}\")"
      ],
      "metadata": {
        "id": "VdjjJGtW4odQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Aplicação *Streamlit* para consumo do Modelo**"
      ],
      "metadata": {
        "id": "zCA4ujj4Iydc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Desenvolvemos uma **aplicação *Streamlit*** que consome o modelo. Na aplicação, o usuário pode **inserir um texto para ser analisado**, ou **enviar um arquivo .xlsx ou .csv para analisar cada um dos textos do arquivo**, devendo **selecionar a coluna que apresenta os textos a serem analisados**.\n",
        "\n",
        "Ao final da execução, **a aplicação apresenta o sentimento do texto analisado** e, caso tenha sido enviado um arquivo, **a aplicação permite que o usuário faça *download* de uma planilha com a coluna de sentimento definido adicionada**.\n",
        "\n",
        "A aplicação foi hospedada no ***Streamlit Cloud*** e pode ser acessada neste [*link*](https://djlmpsentimentanalyzer.streamlit.app/).\n",
        "\n",
        "O código-fonte da aplicação está hospedado no [repositório do projeto](https://github.com/chrnphxbia/djlmp_sentiment_analyzer)."
      ],
      "metadata": {
        "id": "pxBpVptCI_sL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Referências**\n",
        "\n",
        "- Abadi, Martín et al. TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems. 2015. Disponível em: https://www.tensorflow.org/. Acesso em: 01 jun. 2025.\n",
        "\n",
        "- HUGGING FACE. Compartilhando modelos pré-treinados. Disponível em: https://huggingface.co/learn/llm-course/pt/chapter4/3. Acesso em: 1 jun. 2025.\n",
        "\n",
        "- HUGGING FACE. Tokenizer. Disponível em: https://huggingface.co/docs/transformers/main_classes/tokenizer. Acesso em: 1 jun. 2025.\n",
        "\n",
        "- HUGGING FACE. Uploading models. Disponível em: https://huggingface.co/docs/hub/models-uploading. Acesso em: 1 jun. 2025.\n",
        "\n",
        "- SILVA, Luciano José da et al. Tweet_Eleições_2022: Um dataset de tweets durante as eleições presidenciais brasileiras de 2022. In: BRAZILIAN WORKSHOP ON SOCIAL NETWORK ANALYSIS AND MINING (BRASNAM), 13., 2024, Brasília/DF. Anais [...]. Porto Alegre: Sociedade Brasileira de Computação, 2024. p. 193-199. DOI 10.5753/brasnam.2024.1940. Disponível em: https://sol.sbc.org.br/index.php/brasnam/article/view/29343. Acesso em: 30 maio 2025.\n",
        "\n",
        "- SOUZA, Fábio. neuralmind/bert-base-portuguese-cased. [S. l.]: Hugging Face, 2020. Disponível em: https://huggingface.co/neuralmind/bert-base-portuguese-cased. Acesso em: 1 jun. 2025.\n",
        "\n",
        "- TALEBI, S. Fine-Tuning BERT for Text Classification (w/ Example Code). [Publicado em 17 de out. de 2024]. Disponível em: http://www.youtube.com/watch?v=4QHg8Ix8WWQ. Acesso em: 1 de jun. de 2025.\n",
        "\n",
        "- WOLF, Thomas et al. HuggingFace's Transformers: State-of-the-art Natural Language Processing. CoRR, v. abs/1910.03771, 2019. Disponível em: http://arxiv.org/abs/1910.03771. Acesso em: 1 jun. 2025.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "7LtXrRFr4hg3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8crUBC3IQ3U_"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BluFtfHuCGzm"
      },
      "source": [
        "# @title **Avaliação**\n",
        "GitHub = 10 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Implementacao_Model_Code = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Aplicacao_Streamlit = 9 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Texto_Artigo  = 6 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Video = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "Geral = 7 #@param {type:\"slider\", min:0, max:10, step:1}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Gqw7hUZHyle",
        "cellView": "form"
      },
      "source": [
        "#@title **Nota Final**\n",
        "\n",
        "nota = 2*GitHub + 4*Implementacao_Model_Code + 2*Aplicacao_Streamlit + 1*Texto_Artigo + 1*Video\n",
        "\n",
        "nota = nota / 10\n",
        "\n",
        "print(f'Nota final do trabalho {nota :.1f}')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "alunos = pd.DataFrame()\n",
        "\n",
        "lista_tia = []\n",
        "lista_nome = []\n",
        "\n",
        "for i in range(1,6):\n",
        "  exec(\"if Aluno\" + str(i) + \" !='None':  lista = Aluno\" + str(i) + \".split(','); lista_tia.append(lista[0]); lista_nome.append(lista[1].upper())\")\n",
        "\n",
        "alunos['tia'] = lista_tia\n",
        "alunos['nome'] = lista_nome\n",
        "alunos['nota'] = np.round(nota,1)\n",
        "print()\n",
        "display(alunos)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}